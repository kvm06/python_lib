1. Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?
Регуляризация заключается в штрафовании моделей, чтобы ограничить их переобучение. Для регуляризации в деревьях решений применяется ограничение различных параметров: глубина дерева, минимальный вес листа. 
Для лесов деревьев применяются также такие параметры регуляризации как скорость обучения, отсев, ранняя остановка.  
Скорость обучения (learning rate) — коэффициент, который показывает, насколько подробно нужно уточнять свои результаты с каждым шагом. едет к переобучению. 
Отсев (dropout) — параметр, которым задается относительная часть всех данных, скрытая случайным образом во время обучения.
Ранняя остановка (early stopping) — это стратегия, при которой мы возвращаемся к последней лучшей итерации в случае, если после нескольких итераций подряд точность модели на скрытых валидационных данных не улучшилась. 

2. По какому принципу рассчитывается "важность признака (feature_importance)" в ансамблях деревьев?
Важность признака вычисляется как (нормализованное) общее уменьшение критерия, вызванного этим признаком.  
Уменьшение критерия вычисляется по формуле: 
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
где N общее количество примеров, N_t is количество примеров в текущем узле, N_t_L количество примеров в левом дочернем элементе,  N_t_R is число примеров в правом дочернем элементе.

